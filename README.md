# Credit Risk Analysis Report
The purpose of this analysis report to describe what was done in Module 20 of course to acheive the results and what those results were. This module was about supervised machine learning and the task was to train a model based on loan risk. In other words, the point of this exercise was to make a model using data based on the historical lending activity from a peer-to-peer lending services company to identify the creditworthiness of borrowers. The first thing that was done was to download the lending_data.csv and make a file path so that a dataframe could be created into Jupyter Notebook. Once that was completed, the data was then separated into labels and features in which the labels set (y) from the "loan_status" column. After a review of both the x variable dataframe and y variable series, the value_counts() function was used to check the balance of the target values. the data was then split into testing and training datasets with a random state of 1. After the datasets were split, the training data could now be used to instantiate the logistic regression model with a random stat parameter of 1. Now, a prediction could be made using the test data by using pred = LR.predict(X_test). Using the balanced_accuracy_score imported from sklearn.metrics, we were able to make a test prediction which resluted in an over 95% accuracy score. Next, a confusion matrix was made and a classification report was printed. The Logistic Regression Model proved to be highly accurate with an over 90% in predicting both the 0 (healthy loan) and 1 (high-risk loan) labels. I then had to predict a logistic regression model with resampled training data. To make the resampled data, I instantiate the random oversampler model and assigned a random state parameter of 1. Afterwards, I fit the orginal training training data to the random oversampler model to help make the resampled data. This had to be done as earlier the orginal training was oversampling healthy loan labels. By resampling the training data, I made the helathy loan labels and the high risk labels equal so as to elimate bias in the dataset. I think counted the distinct values of the resampled labels data. Using the value_counts() function, I was able to confirm that the resampling had equalized the amount of healthy and high risk labels. I then instantiated the logistic regression model, assigned it a random state parameter of 1, fit the model using the resampled data, and made a prediction. Using balanced_accuracy_score, I returned an accuracy score of over 99%. I generated a confusion matrix again for the resampled data and printed the classification report. 
To summuraize with the results of the classification report, 

                  precision    recall  f1-score   support

           0       0.99        0.99     0.99      75036
           1       0.99        0.99     0.99      75036

    accuracy                            0.99      150072
   macro avg       0.99        0.99     0.99      150072
weighted avg       0.99        0.99     0.99      150072

Would I recommend the company in question to use this model to determine if someone was worth lending money to. I would say that using this model is more than accurate enough to determine if someone was too much of a risk to lend them money or credit. With both the original and the resampled data, I was able to determine with over 95% accuracy the healty labels from the high risk ones.
